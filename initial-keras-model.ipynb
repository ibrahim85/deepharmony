{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Initial Keras model\n",
    "\n",
    "Simple keras model to make sure that I know how everything can fit together.\n",
    "\n",
    "I threw together the `separateVoices` code and the preprocessing code (changed to match `separateVoices` naming convention) and ran it through a keras model... not any keras model we care about though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import music21 as m21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song = m21.converter.parse('data/bach-chorales/bach-1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"separateVoices may put the same note in two different voices...\n",
    "\n",
    "when getElementsByOffset is called in a situation like:\n",
    "1   2   3   4\n",
    "XXX XXX\n",
    "YYY YYY\n",
    "    ZZZ\n",
    "WWW WWW\n",
    "\n",
    "Note W will be added to both the Tenor and the Bass part\n",
    "\"\"\"\n",
    "\n",
    "def separateVoices(song):\n",
    "    timeSig = song.recurse().getElementsByClass('TimeSignature')[0]\n",
    "    tempo = song.recurse().getElementsByClass('MetronomeMark')[0]\n",
    "\n",
    "    sepVoices = m21.stream.Score()\n",
    "\n",
    "    parts = []\n",
    "    for voice in ['Soprano','Alto','Tenor','Bass']:\n",
    "        part = m21.stream.Part()\n",
    "        part.partName = voice\n",
    "        part.append(timeSig)\n",
    "        part.append(tempo)\n",
    "        #part.append(m21.clef.TrebleClef() #just for readability\n",
    "        parts.append(part)\n",
    "\n",
    "    sepVoices.append(parts)\n",
    "\n",
    "    # takes Chord, returns list of component Notes\n",
    "    def chord2notes(chord):\n",
    "        return [m21.note.Note(pitch, duration=chord.duration) for pitch in chord.pitches]\n",
    "\n",
    "    # Replace chords with notes\n",
    "    def removeChords(stream):\n",
    "        import copy\n",
    "        newStream = copy.deepcopy(stream)\n",
    "        for noteOrChord in newStream.flat.notes:\n",
    "            if noteOrChord.isChord:\n",
    "                offset = noteOrChord.offset\n",
    "                newStream.remove(noteOrChord, recurse=True)   \n",
    "\n",
    "                for note in chord2notes(noteOrChord):\n",
    "                    newStream.insert(offset,note)\n",
    "        return newStream\n",
    "\n",
    "    #Remove all chords\n",
    "    chordless = removeChords(song)\n",
    "\n",
    "    # At each note, identify and separate the voices\n",
    "    for note in chordless.flat.notes:\n",
    "#     for note in chordless.flat.getElementsByOffset(0,11, classList=['Note']):\n",
    "        simulNotes = list(chordless.flat.getElementsByOffset(note.offset, mustBeginInSpan=False, classList=['Note']))\n",
    "        simulNotes.sort(key=lambda x: x.pitch, reverse=True)\n",
    "        \n",
    "\n",
    "        for part, newnote in zip(parts, simulNotes):                \n",
    "            if newnote.id not in [n.id for n in part.flat.notes] and note==newnote:\n",
    "                part.insert(newnote.offset,newnote)\n",
    "                \n",
    "    return sepVoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A0 is 21 and C8 is 108\n",
    "HOLD_NOTE = 20\n",
    "SILENCE = 19\n",
    "\n",
    "\n",
    "# Converts note or chord to a midi pitch (int)\n",
    "def pitch(note):\n",
    "    try:\n",
    "        #... Should probably change this part\n",
    "        return note.pitches[0].midi # If it's a chord, get top note\n",
    "    except AttributeError:\n",
    "        return note.pitch.midi # if it's not a chord\n",
    "\n",
    "\n",
    "# music21.Stream -> [int...]\n",
    "# Converts a 'voice' (with no chords) to series of pitches\n",
    "def makePitchArray(voice):\n",
    "    # Divisions are in quarter notes... we may want to change this\n",
    "    array = []\n",
    "    current_note = 0\n",
    "    for time in range(0, int(voice.duration.quarterLength)):\n",
    "        # Figure out current note\n",
    "        notes = voice.flat.getElementsByOffset(time, mustBeginInSpan=False, classList=['Note'])\n",
    "        if len(notes) == 0:\n",
    "            array.append(SILENCE)\n",
    "        else:\n",
    "            note = notes[0]\n",
    "            if note.offset > time-1:\n",
    "                # The note started in the past quarternote\n",
    "                array.append(note.pitch.midi)\n",
    "            else:\n",
    "                array.append(HOLD_NOTE)\n",
    "    return array\n",
    "\n",
    "# Converts pitch number to a tuple with \"one hot encoding\"\n",
    "LOWEST_PITCH=SILENCE\n",
    "HIGHEST_PITCH=108 # C8\n",
    "def pitchToTuple(pitch):\n",
    "    list = [0] * (HIGHEST_PITCH-LOWEST_PITCH)\n",
    "    list[pitch-LOWEST_PITCH] = 1\n",
    "    return tuple(list)\n",
    "\n",
    "def tupleToPitch(tuple):\n",
    "    index = max(enumerate(tuple), key=lambda x: x[1])[0]\n",
    "    return LOWEST_PITCH + index\n",
    "\n",
    "def pitchToStream(pitch_array):\n",
    "    stream = m21.stream.Stream()\n",
    "    for pitch in pitch_array:\n",
    "        if pitch == HOLD_NOTE:\n",
    "            stream[-1].quarterLength += 1\n",
    "        elif pitch != SILENCE:\n",
    "            stream.append(m21.note.Note(pitch))\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voices = separateVoices(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(song):\n",
    "    voices = separateVoices(song)\n",
    "    tuple_arrays = []\n",
    "    for voice in voices:\n",
    "        pitch_array = makePitchArray(voice)\n",
    "        tuple_arrays.append(list(map(pitchToTuple, pitch_array)))\n",
    "    return tuple_arrays\n",
    "\n",
    "preprocessed = preprocess(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Keras model \n",
    "A naively stupid deep learning model to predict the next note.\n",
    "\n",
    "Most of the keras code comes straight off of the \"Getting Started\" guide on keras.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "207/207 [==============================] - 0s - loss: 4.4420 - acc: 0.0242         \n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 0s - loss: 4.4116 - acc: 0.1353     \n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 0s - loss: 4.3821 - acc: 0.2126     \n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 0s - loss: 4.3527 - acc: 0.4541     \n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 0s - loss: 4.3236 - acc: 0.4928     \n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 0s - loss: 4.2934 - acc: 0.4928     \n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 0s - loss: 4.2644 - acc: 0.4928     \n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 0s - loss: 4.2340 - acc: 0.4928     \n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 0s - loss: 4.2031 - acc: 0.4928     \n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 0s - loss: 4.1729 - acc: 0.4928     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116c44cc0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PITCH_LEN = len(pitchToTuple(SILENCE))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=PITCH_LEN, input_dim=PITCH_LEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=PITCH_LEN))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Train to match the next note\n",
    "data = np.array(preprocessed[0][:-1])\n",
    "labels = np.array(preprocessed[0][1:])\n",
    "model.fit(data, labels, nb_epoch=10, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the stupid keras model to predict  the next pitch given G2#\n",
    "# It should predict SILENCE\n",
    "tupleToPitch(model.predict(np.array([pitchToTuple(32)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
